{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y95EwaJaWj16"
      },
      "source": [
        "## load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyBbRMYKPvu4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGs9gXH3ZjgA",
        "outputId": "ad5309fe-d7fe-4d73-d99a-1132e5129640"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"dev.zip\"):\n",
        "\t!wget \"https://huggingface.co/datasets/gabrielrstan/CORAA-v1.1/resolve/main/dev.zip\" -P \".\"\n",
        "\n",
        "if not os.path.isdir(\"dev/\"):\n",
        "\t!unzip \"dev.zip\" -d \".\"\n",
        "\n",
        "if os.path.isdir(\"dev/\"):\n",
        "\tclear_output()\n",
        "\tprint(\"data unzipped\")\n",
        "else:\n",
        "\t# !rm /content/dev.zip\n",
        "\traise Exception(\"Cannot unzip.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhZavogveUkh",
        "outputId": "08e5787e-c252-4611-dfcf-291865667d1f"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"metadata_dev_final.csv\"):\n",
        "\t!wget \"https://huggingface.co/datasets/gabrielrstan/CORAA-v1.1/resolve/main/metadata_dev_final.csv\" -P \".\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWJ9kzAfRGw7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "L4uqDEjqeY3J",
        "outputId": "ea85da8b-0e36-451c-c9f4-260494dcdac1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('metadata_dev_final.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-UCLjH5sFT_5",
        "outputId": "c0b8fa0a-aef4-4615-f94f-03d15bdc7be7"
      },
      "outputs": [],
      "source": [
        "df[['up_votes', 'down_votes']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoAhWB3YWqLq"
      },
      "source": [
        "## manipulate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "qbxqThbGGI50",
        "outputId": "202fc02c-5adf-4e05-9229-9ebccd2686e6"
      },
      "outputs": [],
      "source": [
        "temp_df = df.copy()\n",
        "temp_df = temp_df[temp_df['up_votes'] > 1]\n",
        "temp_df = temp_df[temp_df['down_votes'] == 0]\n",
        "temp_df = temp_df.reset_index(drop=True)\n",
        "temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IM_cPUu4e_iE",
        "outputId": "38165ded-19c5-437b-89a7-a0669a1c6fcd"
      },
      "outputs": [],
      "source": [
        "df_hesitation = temp_df[['file_path','votes_for_hesitation']].dropna()\n",
        "df_hesitation['has_hesitation'] = (df_hesitation['votes_for_hesitation'] > 0).astype(int)\n",
        "df_hesitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnsu9SKmfwEN"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "\n",
        "# remove audios with min_limite length\n",
        "\n",
        "MINIMUM_DURATION = 2 # seconds\n",
        "MAXIMUM_DURATION = 5 # seconds\n",
        "\n",
        "def audiofile_duration(file_path: str) -> float:\n",
        "\twaveform, sample_rate = librosa.load(file_path)\n",
        "\tduration = librosa.get_duration(y=waveform, sr=sample_rate)\n",
        "\treturn duration\n",
        "\n",
        "def get_df_with_min_max_duration(df:pd.DataFrame, minimum_duration:float, maximum_duration:float) -> pd.DataFrame:\n",
        "\t\"\"\"\n",
        "\tdf: dataframe containing 'file_path'\n",
        "\tminimum_duration: minimum audio duration\n",
        "\t\"\"\"\n",
        "\tdf['audio_duration'] = df['file_path'].map(audiofile_duration)\n",
        "\tdf = df[df['audio_duration'] > minimum_duration]\n",
        "\tdf = df[df['audio_duration'] < maximum_duration]\n",
        "\treturn df.reset_index(drop=True)\n",
        "\n",
        "df_hesitation = get_df_with_min_max_duration(df_hesitation, MINIMUM_DURATION, MAXIMUM_DURATION)\n",
        "df_hesitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCQMIjXjDID5"
      },
      "outputs": [],
      "source": [
        "df_hesitation['has_hesitation'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DlsPmTLDf35"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "\n",
        "has_hesitation_count = df_hesitation['has_hesitation'].value_counts()[1]\n",
        "not_has_hesitation_count = df_hesitation['has_hesitation'].value_counts()[0]\n",
        "to_remove = sample(list(df_hesitation[df_hesitation['has_hesitation'] == 0].index), not_has_hesitation_count-has_hesitation_count)\n",
        "df_hesitation = df_hesitation.drop(to_remove).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rutvFMojAEZC"
      },
      "outputs": [],
      "source": [
        "df_hesitation['has_hesitation'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_hesitation['audio_duration'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if os.path.isdir(\"_df_audios\"):\n",
        "\tshutil.rmtree(\"_df_audios\")\n",
        "os.mkdir(\"_df_audios\")\n",
        "os.mkdir(\"_df_audios/hesitation\")\n",
        "os.mkdir(\"_df_audios/no_hesitation\")\n",
        "\n",
        "def create_df_audios_folder(row):\n",
        "    dest = \"_df_audios/hesitation\" if row['has_hesitation'] == 1 else \"_df_audios/no_hesitation\"\n",
        "    shutil.copy(row['file_path'], dest)\n",
        "    \n",
        "df_hesitation.apply(create_df_audios_folder, axis=1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFU1a0_hW8ml"
      },
      "source": [
        "## setting model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xws5N26IRTGE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
        "from transformers import AutoProcessor, AutoModelForAudioClassification\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNy07RYwRYW2"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\")\n",
        "# processor = AutoProcessor.from_pretrained(\"alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\")\n",
        "\n",
        "def get_model(dropout: float):\n",
        "\t# model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "\tmodel = AutoModelForAudioClassification.from_pretrained(\"alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\")\n",
        "\n",
        "\t# MIT/ast-finetuned-audioset-10-10-0.4593\n",
        "\t# dense_in_features = model.classifier.dense.in_features\n",
        "\t# n_classes = 2\n",
        "\t# model.classifier.dense = nn.Sequential(\n",
        "\t#     nn.Dropout(dropout, inplace=True),\n",
        "\t#     nn.Linear(in_features=dense_in_features, out_features=n_classes),\n",
        "\t# )\n",
        "\n",
        "\n",
        "\t# alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\n",
        "\tdense_in_features = model.classifier.in_features\n",
        "\tn_classes = 2\n",
        "\tmodel.classifier = nn.Sequential(\n",
        "\t\tnn.Dropout(dropout, inplace=True),\n",
        "\t\tnn.Linear(in_features=dense_in_features, out_features=n_classes),\n",
        "\t)\n",
        "\tmodel\n",
        "\n",
        "\n",
        "\tfor param in model.parameters():\n",
        "\t\tparam.requires_grad = True\n",
        "\n",
        "\tfor param in model.classifier.parameters():\n",
        "\t\tparam.requires_grad = True\n",
        "\t\t\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLQUnCPDXEqK"
      },
      "source": [
        "## setting dataset to torch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoDKbcpXXxOi"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def get_features(file_paths:list) -> torch.Tensor:\n",
        "\tsampling_rate = 16_000\n",
        "\twaveforms = []\n",
        "\tfor file_path in file_paths:\n",
        "\t\twaveform, original_samplerate = librosa.load(file_path)\n",
        "\t\twaveform = librosa.resample(waveform, orig_sr=original_samplerate, target_sr=sampling_rate)\n",
        "\t\twaveforms.append(waveform)\n",
        "\n",
        "\t# MIT/ast-finetuned-audioset-10-10-0.4593\n",
        "\t#features = feature_extractor(waveforms, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "\n",
        "\t# alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\n",
        "\tfeatures = feature_extractor(waveforms, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True) #, truncation=True, max_length=10000)\n",
        "\t\n",
        "\treturn features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_xmWa_kbOCn"
      },
      "outputs": [],
      "source": [
        "features = get_features(df_hesitation['file_path'])\n",
        "features['input_values'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nBzFZmLeyfO"
      },
      "outputs": [],
      "source": [
        "features['labels'] = torch.tensor(df_hesitation['has_hesitation'],dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QUOoYnFzYgg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features['input_values'], features['labels'], test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApmVCJR2fKKs"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=12, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9zAHSC2XGsx"
      },
      "source": [
        "## training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7dbFEOB2ziy"
      },
      "outputs": [],
      "source": [
        "def eval_model(model) -> tuple:\n",
        "\t\"\"\"\n",
        "\treturn:\n",
        "\tloss\n",
        "\taccuracy\n",
        "\t\"\"\"\n",
        "\tmodel.eval()\n",
        "\n",
        "\trunning_loss = 0\n",
        "\trunning_corrects = 0\n",
        "\tfor i, (inputs, labels) in enumerate(test_dataloader):\n",
        "\t\tinputs, labels = inputs.to(device), labels.to(device)\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tlogits = model(inputs).logits\n",
        "\t\t\tloss = cross_entropy(logits, labels)\n",
        "\t\t\tpredicted_class = torch.argmax(logits, dim=-1)\n",
        "\n",
        "\t\t\trunning_loss += loss.item()\n",
        "\t\t\trunning_corrects += sum(labels == predicted_class)\n",
        "\tloss = (running_loss/len(test_dataloader))\n",
        "\taccuracy = running_corrects/(len(test_dataloader) * test_dataloader.batch_size)\n",
        "\treturn loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "\n",
        "put_train = ray.put(train_dataloader)\n",
        "put_test = ray.put(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIyIGyxM56Uq"
      },
      "outputs": [],
      "source": [
        "def train_func(model, dataloader, optimizer, exp_lr_scheduler, clip_value):\n",
        "\ttotal = 0\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tmodel.train()\n",
        "\trunning_loss = 0\n",
        "\tcorrect = 0\n",
        "\n",
        "\tpred_np = []\n",
        "\ttarget_np = []\n",
        "\tfor i, (data, target) in enumerate(dataloader):\n",
        "\t\tdata, target = data.to(device), target.to(device)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\toutput = model(data).logits\n",
        "\t\tloss = cross_entropy(output, target)\n",
        "\n",
        "\t\ttotal += output.size(0)\n",
        "\t\trunning_loss += loss.item() * output.size(0)\n",
        "\n",
        "\t\tloss.backward()\n",
        "\n",
        "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "\t\toptimizer.step()\n",
        "\t\t\t# accuracy\n",
        "\t\t_, predicted = torch.max(output.data, 1)\n",
        "\t\t# _, correct_class = torch.max(target.data, 1)\n",
        "\n",
        "\t\tcorrect += (predicted == target).sum().item()\n",
        "\n",
        "\t\tpred_np.append(predicted.detach().cpu().numpy())\n",
        "\t\ttarget_np.append(target.detach().cpu().numpy())\n",
        "\n",
        "\texp_lr_scheduler.step()\n",
        "\n",
        "\n",
        "\tpred_np = np.concatenate(pred_np)\n",
        "\ttarget_np = np.concatenate(target_np)\n",
        "\n",
        "\treturn {\n",
        "\t\t\"mean_loss\": running_loss / total,\n",
        "\t\t\"accuracy\": accuracy_score(target_np, pred_np),\n",
        "\t\t\"f1_score\": f1_score(target_np, pred_np),\n",
        "\t}\n",
        "\n",
        "def test_func(model, dataloader):\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tmodel.eval()\n",
        "\tcorrect = 0\n",
        "\ttotal = 0\n",
        "\trunning_loss = 0\n",
        "\t\n",
        "\tpred_np = []\n",
        "\ttarget_np = []\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch_idx, (data, target) in enumerate(dataloader):\n",
        "\n",
        "\t\t\tdata, target = data.to(device), target.to(device)\n",
        "\t\t\toutputs = model(data).logits\n",
        "\n",
        "\t\t\t# accuracy\n",
        "\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
        "\t\t\t# _, correct_class = torch.max(target.data, 1)\n",
        "\t\t\ttotal += target.size(0)\n",
        "\t\t\tcorrect += (predicted == target).sum().item()\n",
        "\n",
        "\t\t\tpred_np.append(predicted.detach().cpu().numpy())\n",
        "\t\t\ttarget_np.append(target.detach().cpu().numpy())\n",
        "\n",
        "\t\t\t# loss\n",
        "\t\t\trunning_loss += cross_entropy(outputs, target).item() * outputs.size(0)\n",
        "\n",
        "\tpred_np = np.concatenate(pred_np)\n",
        "\ttarget_np = np.concatenate(target_np)\n",
        "\n",
        "\treturn {\n",
        "\t\t\"mean_loss\": running_loss / total,\n",
        "\t\t\"accuracy\": accuracy_score(target_np, pred_np),\n",
        "\t\t\"f1_score\": f1_score(target_np, pred_np),\n",
        "\t}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2eFlco56ypx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "from ray import train\n",
        "from ray.train import Checkpoint\n",
        "\n",
        "def train_hesitation(config, max_epochs=30, tunning=True):\n",
        "\ttrain_dataloader = ray.get(put_train)\n",
        "\ttest_dataloader = ray.get(put_test)\n",
        "\n",
        "\t# Data Setup\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\tmodel = get_model(config['classifier_dropout'])\n",
        "\tmodel.to(device)\n",
        "\n",
        "\toptimizer = optim.SGD(\n",
        "\t\tmodel.parameters(),\n",
        "\t\tlr=config[\"lr\"],\n",
        "\t\tmomentum=config[\"momentum\"],\n",
        "\t\tweight_decay=config['weight_decay'],\n",
        "\t\tnesterov=config['nesterov']\n",
        "\t)\n",
        "\n",
        "\texp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=config['lr_scheduler_gamma'])\n",
        "\tfor i in range(max_epochs):\n",
        "\t\ttrain_log = train_func(model, train_dataloader, optimizer, exp_lr_scheduler, config['clip_value'])\n",
        "\t\tval_log = test_func(model, test_dataloader)\n",
        "\n",
        "\t\tif tunning:\n",
        "\t\t\twith tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
        "\t\t\t\tcheckpoint = None\n",
        "\t\t\t\tif (i + 1) % max_epochs == 0 and (val_log[\"mean_loss\"] < 0.4):\n",
        "\t\t\t\t\t# This saves the model to the trial directory\n",
        "\t\t\t\t\ttorch.save(\n",
        "\t\t\t\t\t\tmodel.state_dict(),\n",
        "\t\t\t\t\t\tos.path.join(temp_checkpoint_dir, \"model.pth\")\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\t\tcheckpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
        "\n",
        "\t\t\t\t# Send the current training result back to Tune\n",
        "\t\t\t\ttrain.report(\n",
        "\t\t\t\t\t{\n",
        "\t\t\t\t\t\t\"train_mean_loss\": train_log[\"mean_loss\"],\n",
        "\t\t\t\t\t\t\"train_accuracy\": train_log[\"accuracy\"],\n",
        "\t\t\t\t\t\t\"train_f1_score\": train_log[\"f1_score\"],\n",
        "\t\t\t\t\t\t\"val_mean_loss\": val_log[\"mean_loss\"],\n",
        "\t\t\t\t\t\t\"val_accuracy\": val_log[\"accuracy\"],\n",
        "\t\t\t\t\t\t\"val_f1_score\": val_log[\"f1_score\"],\n",
        "\t\t\t\t\t},\n",
        "\t\t\t\t\tcheckpoint=checkpoint\n",
        "\t\t\t\t)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"-\"*10, f\"epoch: {i+1}/{max_epochs}\",\"-\"*10)\n",
        "\t\t\tprint(f\"train: {train_log}\\nval: {val_log}\")\n",
        "\tif not tunning:\n",
        "\t\treturn {\n",
        "\t\t\t\"model\": model,\n",
        "\t\t\t\"log\": {\n",
        "\t\t\t\t\"train\": train_log,\n",
        "\t\t\t\t\"val\": val_log,\n",
        "\t\t\t},\n",
        "\t\t}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_cpus = os.cpu_count()\n",
        "max_gpus = torch.cuda.device_count()\n",
        "max_cpus, max_gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ray import tune\n",
        "\n",
        "from ray.tune.search.optuna import OptunaSearch\n",
        "\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "\n",
        "config = {\n",
        "\t\"lr\": tune.loguniform(1e-5, 1e-0),\n",
        "\t\"momentum\": tune.uniform(0.1, 0.9),\n",
        "\t\"classifier_dropout\": tune.uniform(0.3, 0.7),\n",
        "\t\"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
        "\t\"clip_value\": tune.randint(1, 5+1),\n",
        "\t\"lr_scheduler_gamma\": tune.uniform(0.5, 1.0),\n",
        "\t\"nesterov\": tune.choice([True, False]),\n",
        "}\n",
        "\n",
        "metric = \"val_mean_loss\"\n",
        "mode = \"min\"\n",
        "\n",
        "optuna_search = OptunaSearch(\n",
        "\tmetric=metric,\n",
        "\tmode=mode,\n",
        "\t# points_to_evaluate = curr_best_params,\n",
        ")\n",
        "\n",
        "asas_scheduler = ASHAScheduler(\n",
        "\ttime_attr='training_iteration',\n",
        "\tmetric=metric,\n",
        "\tmode=mode,\n",
        "\tmax_t=10,\n",
        "\tgrace_period=1,\n",
        "\treduction_factor=3,\n",
        "\tbrackets=2\n",
        ")\n",
        "\n",
        "trainable_with_resources = tune.with_resources(train_hesitation, {\"cpu\": max_cpus, \"gpu\": max_gpus})\n",
        "\n",
        "tuner = tune.Tuner(\n",
        "\ttrainable_with_resources,\n",
        "\ttune_config=tune.TuneConfig(\n",
        "\t\tnum_samples=20,\n",
        "\t\tsearch_alg=optuna_search,\n",
        "\t\tscheduler=asas_scheduler\n",
        "\t),\n",
        "\tparam_space=config,\n",
        ")\n",
        "results = tuner.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.get_dataframe().to_csv(\"raytune_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results = results.get_dataframe()\n",
        "df_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = df_results['val_f1_score'].plot(kind='hist', title='f1_score hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_result = results.get_best_result(\"val_accuracy\", mode=\"max\")\n",
        "best_result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_result = results.get_best_result(\"val_mean_loss\", mode=\"min\")\n",
        "best_result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"best_result.json\", 'w') as f:\n",
        "\tjson.dump(best_result.config, f, default=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_config_train_model = train_hesitation(best_result.config, max_epochs=10, tunning=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nukqKS2AXKqj"
      },
      "source": [
        "## evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = best_config_train_model['model']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aicm9Xz_9e6r"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "\tinputs, labels = inputs.to(device), labels.to(device)\n",
        "\twith torch.no_grad():\n",
        "\t\tlogits = model(inputs).logits\n",
        "\t\tpredicted_class_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "\tall_labels.append(labels)\n",
        "\tall_preds.append(predicted_class_ids)\n",
        "\n",
        "all_labels = torch.concat(all_labels).cpu()\n",
        "all_preds = torch.concat(all_preds).cpu()\n",
        "\n",
        "all_labels.shape, all_preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IxUchOXECpw"
      },
      "outputs": [],
      "source": [
        "classes_names = ['ausent', 'hesitation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H88ihItxCxY4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BttAIybDbNL"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes_names)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "print(classification_report(all_labels, all_preds, target_names=classes_names))\n",
        "print(\"\\naccuracy:\", accuracy_score(all_labels, all_preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
